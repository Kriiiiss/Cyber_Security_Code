{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8f187b-203b-4140-8827-63bacacb8484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 06:19:12.033554: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 06:19:12.036073: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 06:19:12.067657: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 06:19:12.745584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "2024-04-02 06:19:15.378326: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.backend' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 34\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mKerasClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmin_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, nb_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier on the test set\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/art/estimators/classification/keras.py:129\u001b[0m, in \u001b[0;36mKerasClassifier.__init__\u001b[0;34m(self, model, use_logits, channels_first, clip_values, preprocessing_defences, postprocessing_defences, preprocessing, input_layer, output_layer)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType of model not recognized:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model)))\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/art/estimators/classification/keras.py:260\u001b[0m, in \u001b[0;36mKerasClassifier._initialize_params\u001b[0;34m(self, model, use_logits, input_layer, output_layer)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(loss_function)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m loss_function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     ]\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m flag_is_instance:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     label_ph \u001b[38;5;241m=\u001b[39m \u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m(shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(loss_function) \u001b[38;5;129;01mand\u001b[39;00m loss_function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    263\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_function, keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.backend' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Trains a convolutional neural network on the MNIST dataset, then attacks it with the FGSM attack.\"\"\"\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.utils import load_dataset\n",
    "\n",
    "# Read MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"mnist\"))\n",
    "\n",
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=5, batch_size=128)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "preds = np.argmax(classifier.predict(x_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy: %.2f%%\" % (acc * 100))\n",
    "\n",
    "# Define epsilon values\n",
    "epsilon_values = [0.01, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Iterate over epsilon values\n",
    "for epsilon in epsilon_values:\n",
    "    # Craft adversarial samples with FGSM\n",
    "    adv_crafter = BasicIterativeMethod(classifier, eps=epsilon, verbose = False)\n",
    "    x_test_adv = adv_crafter.generate(x=x_test, y=y_test)\n",
    "\n",
    "    # Evaluate the classifier on the adversarial examples\n",
    "    preds = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "    print(\"Test accuracy on adversarial sample (epsilon = %.2f): %.2f%%\" % (epsilon, acc * 100))\n",
    "\n",
    "    y_hat = preds\n",
    "    y_test_arg = np.argmax(y_test, axis=1)\n",
    "    conf_matrix = confusion_matrix(y_test_arg, y_hat)\n",
    "    # tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    cm = conf_matrix\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)\n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "    \n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    fnr = fn / (fn + tp)\n",
    "    tnr = tn / (tn + fp)\n",
    "    precision = precision_score(y_test_arg, y_hat, average='macro')\n",
    "    accuracy = accuracy_score(y_test_arg, y_hat)\n",
    "    f1 = f1_score(y_test_arg, y_hat, average='weighted')\n",
    "    # auc = roc_auc_score(y_test_arg, cnn_model.predict(x_test), multi_class='ovr')\n",
    "    \n",
    "    print(f\"FPR: {fpr}\")\n",
    "    print(f\"TPR: {tpr}\")\n",
    "    print(f\"FNR: {fnr}\")\n",
    "    print(f\"TNR: {tnr}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    # print(f\"AUC: {auc}\")\n",
    "    \n",
    "    print(f\"FPR: {np.mean(fpr)}\")\n",
    "    print(f\"tpr: {np.mean(tpr)}\")\n",
    "    print(f\"fnr: {np.mean(fnr)}\")\n",
    "    print(f\"tnr: {np.mean(tnr)}\")\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = {\n",
    "        \"model\" : \"cnn\",\n",
    "        \"attack_model\" : \"BasicIterativeMethod\",\n",
    "        \"epsilon\" : epsilon,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"F1-score\": f1,\n",
    "        \"FPR\": np.mean(fpr),\n",
    "        \"TPR\": np.mean(tpr),\n",
    "        \"FNR\": np.mean(fnr),\n",
    "        \"TNR\": np.mean(tnr),\n",
    "        # \"AUC\": auc\n",
    "    }\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_df.to_csv(\"/home/jovyan/MNIST/model.csv\", mode='a', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
