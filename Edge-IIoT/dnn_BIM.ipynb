{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8017151-d095-441c-8fe1-2349ec2c66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install art\n",
    "# !pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46fff69d-5d7c-4c6f-b4c1-0e85ff50dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 15:25:37.041843: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 15:25:37.044372: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 15:25:37.077548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 15:25:37.758146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D\n",
    "from art.estimators.classification import KerasClassifier, TensorFlowV2Classifier\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_test = np.load('/home/jovyan/Edge-IIoT/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/Edge-IIoT/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/Edge-IIoT/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Edge-IIoT/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Edge-IIoT/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Edge-IIoT/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3ae1af-7581-41e7-bee9-36ff73dc6504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-04-02 15:25:40.093970: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.8403 - val_accuracy: 0.9808 - val_loss: 0.0708\n",
      "Epoch 2/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9849 - loss: 0.0540 - val_accuracy: 0.9837 - val_loss: 0.0525\n",
      "Epoch 3/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9852 - loss: 0.0403 - val_accuracy: 0.9856 - val_loss: 0.0398\n",
      "Epoch 4/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9878 - loss: 0.0336 - val_accuracy: 0.9856 - val_loss: 0.0390\n",
      "Epoch 5/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0317 - val_accuracy: 0.9856 - val_loss: 0.0360\n",
      "Epoch 6/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9867 - loss: 0.0358 - val_accuracy: 0.9856 - val_loss: 0.0374\n",
      "Epoch 7/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9882 - loss: 0.0321 - val_accuracy: 0.9856 - val_loss: 0.0360\n",
      "Epoch 8/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0311 - val_accuracy: 0.9856 - val_loss: 0.0366\n",
      "Epoch 9/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9877 - loss: 0.0299 - val_accuracy: 0.9856 - val_loss: 0.0404\n",
      "Epoch 10/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9892 - loss: 0.0286 - val_accuracy: 0.9856 - val_loss: 0.0386\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TensorFlowV2Classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     16\u001b[0m dnn_model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     17\u001b[0m                      validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val),\n\u001b[1;32m     18\u001b[0m                      callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n\u001b[0;32m---> 20\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mTensorFlowV2Classifier\u001b[49m(model\u001b[38;5;241m=\u001b[39mdnn_model, nb_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     21\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m52\u001b[39m,),\n\u001b[1;32m     22\u001b[0m     loss_object\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(),)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128,validation_data=(x_val, y_val),\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#                      callbacks=[early_stopping])\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# y_hat = dnn_model.predict(x_test)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# y_hat = np.argmax(y_hat, axis=-1)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TensorFlowV2Classifier' is not defined"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(50, input_shape=input_shape, activation='relu'))\n",
    "dnn_model.add(Dense(units=30, activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=num_classes, activation='softmax'))\n",
    "dnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "\n",
    "dnn_model.fit(x_train, y_train, epochs=10, batch_size=128,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     callbacks=[early_stopping])\n",
    "\n",
    "classifier = TensorFlowV2Classifier(model=dnn_model, nb_classes=4,\n",
    "    input_shape=(52,),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy(),)\n",
    "# classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128,validation_data=(x_val, y_val),\n",
    "#                      callbacks=[early_stopping])\n",
    "\n",
    "# hist = dnn_model.fit(x_train, y_train, epochs=10, batch_size=128,\n",
    "#                      validation_data=(x_val, y_val),\n",
    "#                      callbacks=[early_stopping])\n",
    "\n",
    "# test_loss, test_acc = dnn_model.evaluate(x_test, y_test)\n",
    "# print('Test accuracy:', test_acc)\n",
    "\n",
    "# y_hat = dnn_model.predict(x_test)\n",
    "# y_hat = np.argmax(y_hat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7081b5-d4ee-4e22-b173-c29eed03be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "\n",
    "epsilon_values = [0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# Iterate over epsilon values\n",
    "for epsilon in epsilon_values:\n",
    "    # Craft adversarial samples with FGSM\n",
    "    adv_crafter = BasicIterativeMethod(classifier, eps=epsilon, batch_size = 64, verbose = False)\n",
    "    x_test_adv = adv_crafter.generate(x=x_test, y=y_test)\n",
    "\n",
    "    filename = f'/home/jovyan/Edge-IIoT/transfer_attackmodel/x_test_adv_BIM_eps_{epsilon}.npy'\n",
    "    np.save(filename, x_test_adv)\n",
    "\n",
    "    # Evaluate the classifier on the adversarial examples\n",
    "    preds = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    # acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "    # print(\"Test accuracy on adversarial sample (epsilon = %.2f): %.2f%%\" % (epsilon, acc * 100))\n",
    "\n",
    "    y_hat = preds\n",
    "    # y_test_arg = np.argmax(y_test, axis=1)\n",
    "    y_test_arg = y_test\n",
    "    conf_matrix = confusion_matrix(y_test_arg, y_hat)\n",
    "    # tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    cm = conf_matrix\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)\n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "    \n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    fnr = fn / (fn + tp)\n",
    "    tnr = tn / (tn + fp)\n",
    "    accuracy = accuracy_score(y_test_arg, y_hat)\n",
    "    precision_macro = precision_score(y_test_arg, y_hat, average='macro')\n",
    "    precision_micro = precision_score(y_test_arg, y_hat, average='micro')\n",
    "    precision_weighted = precision_score(y_test_arg, y_hat, average='weighted')\n",
    "    f1_weighted = f1_score(y_test_arg, y_hat, average='weighted')\n",
    "    f1_macro = f1_score(y_test_arg, y_hat, average='macro')\n",
    "    f1_micro = f1_score(y_test_arg, y_hat, average='micro')\n",
    "    # auc = roc_auc_score(y_test_arg, y_hat, multi_class='ovr')\n",
    "    print(f\"epsilon = {epsilon}\")\n",
    "    print(f\"FPR: {fpr}\")\n",
    "    print(f\"TPR: {tpr}\")\n",
    "    print(f\"FNR: {fnr}\")\n",
    "    print(f\"TNR: {tnr}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision(micro,macro,weighted): {precision_micro},{precision_macro},{precision_weighted}\")\n",
    "    print(f\"F1(micro,macro,weighted: {f1_micro},{f1_macro},{f1_weighted}\")\n",
    "    # print(f\"AUC: {auc}\")\n",
    "    \n",
    "    print(f\"FPR: {np.mean(fpr)}\")\n",
    "    print(f\"tpr: {np.mean(tpr)}\")\n",
    "    print(f\"fnr: {np.mean(fnr)}\")\n",
    "    print(f\"tnr: {np.mean(tnr)}\")\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = {\n",
    "        \"model\" : \"dnn\",\n",
    "        \"attack_model\" : \"BIM\",\n",
    "        \"epsilon\" : epsilon,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision-micro\": precision_micro,\n",
    "        \"Precision-macro\": precision_macro,\n",
    "        \"Precision-weighted\": precision_weighted,\n",
    "        \"F1-micro\": f1_micro,\n",
    "        \"F1-macro\": f1_macro,\n",
    "        \"F1-weighted\": f1_weighted,\n",
    "        \"FPR\": np.mean(fpr),\n",
    "        \"TPR\": np.mean(tpr),\n",
    "        \"FNR\": np.mean(fnr),\n",
    "        \"TNR\": np.mean(tnr),\n",
    "        # \"AUC\": auc\n",
    "    }\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_df.to_csv(\"/home/jovyan/Edge-IIoT/model.csv\", mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7d942-7773-4e8f-a135-a4f107195258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
