{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d00dca0-8488-4ea8-bd40-830625c194bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_test = np.load('/home/jovyan/Wustl_iiot/x_test.npy')\n",
    "X_train = np.load('/home/jovyan/Wustl_iiot/x_train.npy')\n",
    "X_val = np.load('/home/jovyan/Wustl_iiot/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Wustl_iiot/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Wustl_iiot/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Wustl_iiot/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c329fa69-dc96-459e-a890-07c22f4d17c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.0123, Validation Loss: 0.0009, Validation Accuracy: 0.9999\n",
      "Epoch 2, Training Loss: 0.0004, Validation Loss: 0.0008, Validation Accuracy: 0.9999\n",
      "Epoch 3, Training Loss: 0.0004, Validation Loss: 0.0005, Validation Accuracy: 0.9999\n",
      "Epoch 4, Training Loss: 0.0003, Validation Loss: 0.0002, Validation Accuracy: 0.9999\n",
      "Epoch 5, Training Loss: 0.0002, Validation Loss: 0.0002, Validation Accuracy: 0.9999\n",
      "Epoch 6, Training Loss: 0.0001, Validation Loss: 0.0016, Validation Accuracy: 0.9998\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_shape = X_train.shape[1]\n",
    "output_shape = len(np.unique(y_train))\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "dnn_model = DNNModel(input_size=input_shape, output_size=output_shape).to(device)\n",
    "\n",
    "# Compile model\n",
    "optimizer = optim.Adam(dnn_model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping variables\n",
    "min_delta = 0.001\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(15):\n",
    "    dnn_model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = dnn_model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    dnn_model.eval()\n",
    "    val_train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = dnn_model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_train_loss / len(val_loader)\n",
    "    val_accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping check using min_delta\n",
    "    if best_loss - avg_val_loss > min_delta:\n",
    "        best_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fed34d5-2025-4451-9f3d-f8473d0e9834",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_shape = X_train.shape[1:]\n",
    "# num_classes = len(np.unique(y_train))\n",
    "\n",
    "\n",
    "# dnn_model = Sequential()\n",
    "# dnn_model.add(Input(shape=input_shape))\n",
    "# dnn_model.add(Dense(units=30, activation='relu'))\n",
    "# dnn_model.add(Dense(units=20, activation='relu'))\n",
    "# dnn_model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# opt = SGD(learning_rate=0.01)\n",
    "\n",
    "# dnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "# hist = dnn_model.fit(X_train, y_train, epochs=15, batch_size=64,\n",
    "#                      validation_data=(X_val, y_val),\n",
    "#                      callbacks=[early_stopping])\n",
    "\n",
    "# # test_loss, test_acc = dnn_model.evaluate(x_test, y_test)\n",
    "# # print('Test accuracy:', test_acc)\n",
    "\n",
    "# # y_hat = dnn_model.predict(x_test)\n",
    "# # y_hat = np.argmax(y_hat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "337a6cd9-b7b6-4e39-bbbe-d41384158dcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "from a2pm import A2PMethod\n",
    "from a2pm.callbacks import BaseCallback, MetricCallback, TimeCallback\n",
    "from a2pm.patterns import BasePattern, CombinationPattern, IntervalPattern\n",
    "from a2pm.wrappers import BaseWrapper, KerasWrapper, SklearnWrapper, TorchWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9801a71-694e-4dc4-a8db-07a1c01ca906",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def calculate_performance_metrics(model, X_test, y_test, type):\n",
    "#     metrics_weighted(model, X_test, y_test, type)\n",
    "#     metrics_macro(model, X_test, y_test, type)\n",
    "\n",
    "# def metrics_macro(model, X_test, y_test, type):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred, average='macro')\n",
    "#     recall = recall_score(y_test, y_pred, average='macro')\n",
    "#     f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "#     data = {\n",
    "#     \"Metric\": [\"Accuracy\", \"Macro Precision\", \"Macro Recall\", \"Macro F1 Score\"],\n",
    "#     type: [accuracy, precision, recall, f1]\n",
    "#     }\n",
    "    \n",
    "#     # Creating DataFrame\n",
    "#     df = pd.DataFrame(data)\n",
    "    \n",
    "#     # Saving to CSV\n",
    "#     csv_file_path = \"/home/jovyan/A2PM/DNN.csv\"\n",
    "#     df.to_csv(csv_file_path, mode='a', index=False)\n",
    "\n",
    "#     print(type)\n",
    "#     print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "#     print(f\"Macro Precision: {precision * 100:.2f}%\")\n",
    "#     print(f\"Macro Recall: {recall * 100:.2f}%\")\n",
    "#     print(f\"Macro F1 Score: {f1 * 100:.2f}%\")\n",
    "    \n",
    "# def metrics_weighted(model, X_test, y_test, type):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    \n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#     recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#     f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "#     data = {\n",
    "#     \"Metric\": [\"Accuracy\", \"Weighted Precision\", \"Weighted Recall\", \"Weighted F1 Score\"],\n",
    "#     type: [accuracy, precision, recall, f1]\n",
    "#     }\n",
    "    \n",
    "#     # Creating DataFrame\n",
    "#     df = pd.DataFrame(data)\n",
    "    \n",
    "#     # Saving to CSV\n",
    "#     csv_file_path = \"/home/jovyan/A2PM/DNN.csv\"\n",
    "#     df.to_csv(csv_file_path, mode='a', index=False)\n",
    "\n",
    "#     print(type)\n",
    "#     print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "#     print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "#     print(f\"Weighted Recall: {recall * 100:.2f}%\")\n",
    "#     print(f\"Weighted F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "219f54e3-3020-4a53-9137-5650fcce70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(model, X_test, y_true, type):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        probabilities = np.array(probabilities)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "        macro_auc = roc_auc_score(label_binarize(all_labels, classes=range(num_classes)), probabilities, average='macro', multi_class='ovr')\n",
    "        weighted_auc = roc_auc_score(label_binarize(all_labels, classes=range(num_classes)), probabilities, average='weighted', multi_class='ovr')\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "        def calculate_class_metrics_macro(cm, class_index):\n",
    "            TP = cm[class_index, class_index]\n",
    "            FP = cm[:, class_index].sum() - TP\n",
    "            FN = cm[class_index, :].sum() - TP\n",
    "            TN = cm.sum() - (TP + FP + FN)\n",
    "            \n",
    "            TPR = TP / (TP + FN) if (TP + FN) != 0 else 0  \n",
    "            TNR = TN / (TN + FP) if (TN + FP) != 0 else 0  \n",
    "            FPR = FP / (FP + TN) if (FP + TN) != 0 else 0  \n",
    "            FNR = FN / (FN + TP) if (FN + TP) != 0 else 0  \n",
    "            \n",
    "            return TPR, TNR, FPR, FNR\n",
    "            \n",
    "        metrics = np.array([calculate_class_metrics_macro(cm, i) for i in range(num_classes)])\n",
    "        TPR_macro, TNR_macro, FPR_macro, FNR_macro = np.mean(metrics, axis=0)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "        print(\"\\nmacro\")\n",
    "        print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\\nAUC: {macro_auc}\")\n",
    "    \n",
    "        print(\"\\nweighted\")\n",
    "        print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\\nAUC: {weighted_auc}\")\n",
    "        print()\n",
    "        data = {\n",
    "            \"Metric\": [\"Accuracy\", \"Weighted Precision\", \"Weighted Recall\", \"Weighted F1 Score\", \"Macro Precision\", \"Macro Recall\", \"Macro F1 Score\"],\n",
    "            type: [accuracy, precision_weighted, recall_weighted, f1_weighted, precision_macro, recall_macro, f1_macro]\n",
    "            }\n",
    "            \n",
    "        # Creating DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Saving to CSV\n",
    "        csv_file_path = \"/home/jovyan/A2PM/DNN.csv\"\n",
    "        df.to_csv(csv_file_path, mode='a', index=False)\n",
    "        \n",
    "        print(f\"Mean FNR: {FNR_macro}\\nMean TNR: {TNR_macro}\\nMean FPR: {FPR_macro}\\nMean TPR: {TPR_macro}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd99d44c-7996-4ed4-9c57-f782ff9932d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9998911008448061\n",
      "\n",
      "macro\n",
      "Precision: 0.976155262079681\n",
      "Recall: 0.978654109048809\n",
      "F1 Score: 0.9773566078256948\n",
      "AUC: 0.9952368935227277\n",
      "\n",
      "weighted\n",
      "Precision: 0.9998918700672321\n",
      "Recall: 0.9998911008448061\n",
      "F1 Score: 0.9998913010771628\n",
      "AUC: 0.999969085333545\n",
      "\n",
      "Mean FNR: 0.021345890951190927\n",
      "Mean TNR: 0.9999355020394752\n",
      "Mean FPR: 6.449796052489633e-05\n",
      "Mean TPR: 0.978654109048809\n"
     ]
    }
   ],
   "source": [
    "# dnn_model = grid_search_xgb.best_estimator_\n",
    "calculate_performance_metrics(dnn_model, X_test, y_test, \"original score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abb59c35-1623-4753-bbdd-7478c0cea92a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_binary_columns(X_train):\n",
    "    binary_columns = []\n",
    "    for col in range(X_train.shape[1]):\n",
    "        unique_values = np.unique(X_train[:, col])\n",
    "        if set(unique_values).issubset({0, 1}):\n",
    "            binary_columns.append(col)\n",
    "    return binary_columns\n",
    "\n",
    "binary_columns = find_binary_columns(X_train)\n",
    "\n",
    "numerical_columns = []\n",
    "for i in range(0,42):\n",
    "    if i not in binary_columns:\n",
    "        numerical_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ddbeda9-c2c5-4d63-89ac-6595b185d4fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgb_base = grid_search_xgb.best_estimator_\n",
    "\n",
    "# classifier = SklearnWrapper(dnn_model)\n",
    "\n",
    "\n",
    "# rule of thumb: Interval for numerical, combination for categorical\n",
    "pattern = (\n",
    "    {\n",
    "        \"type\": \"interval\",\n",
    "        \"features\": numerical_columns,\n",
    "        #\"integer_features\": list(range(10, 20)),\n",
    "        \"ratio\": 0.1,\n",
    "        \"max_ratio\": 0.3,\n",
    "        \"missing_value\": 0.0,\n",
    "        \"probability\": 1,\n",
    "    },\n",
    "    # {\n",
    "    #     \"type\": \"combination\",\n",
    "    #     \"features\": binary_columns,\n",
    "    #     #\"locked_features\": list(range(30, 40)), # Locks some features to ensure validity. Not using this because data is .npy and unreadable\n",
    "    #     \"probability\": 0.4,\n",
    "    # },\n",
    ")\n",
    "\n",
    "method = A2PMethod(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d14631bf-3207-40b0-a16f-f54af5ffa462",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a924b8cd-7abf-4504-b865-cf69b6fc6c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(955009, 42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cdf8098-a4ff-45dd-98dc-8148edc6bd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716256, 42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4118f38b-1399-47e9-b6aa-59abbbf722df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array-like provided in 'X' must be in the (n_samples, n_features) shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m X_adversarial \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttack Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/a2pm/a2pm.py:733\u001b[0m, in \u001b[0;36mA2PMethod.fit_generate\u001b[0;34m(self, classifier, X, y, y_target, iterations, patience, callback)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mdelattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/a2pm/a2pm.py:805\u001b[0m, in \u001b[0;36mA2PMethod.partial_fit_generate\u001b[0;34m(self, classifier, X, y, y_target, iterations, patience, callback)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpartial_fit_generate\u001b[39m(\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    739\u001b[0m     classifier,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m     callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    746\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    747\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Partially adapts the method to new data,\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03m    and then applies it to perform adversarial attacks against a classifier.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;124;03m        Adversarial data, in the same order as input data.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    806\u001b[0m         classifier, X, y, y_target, iterations, patience, callback\n\u001b[1;32m    807\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/a2pm/a2pm.py:144\u001b[0m, in \u001b[0;36mA2PMethod.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Partially adapts the method to new data.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mFor new found classes, the default pattern will be assigned and updated.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    This A2PMethod instance.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Note 1: If y is not provided, the class discriminator is called\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Note 2: If A2PMethod has not been fitted yet, also performs a setup\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m X, rows_per_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_row_indices_per_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_cls \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)):\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# Obtain pattern tuple and row indices of each class\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     ptn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mapping_[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[i_cls]]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/a2pm/a2pm.py:886\u001b[0m, in \u001b[0;36mA2PMethod.__get_row_indices_per_class\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_row_indices_per_class\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# Private method: Obtains valid X and a list of 'row indices per class'.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# If A2PMethod has not been fitted yet, also performs a setup\u001b[39;00m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# of the pre-assigned patterns and assigns\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# the default pattern to new found classes.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# Returns: Tuple[np.ndarray, list]\u001b[39;00m\n\u001b[0;32m--> 886\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_valid_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;66;03m# Setup class mapping\u001b[39;00m\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mapping_ \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/a2pm/a2pm.py:846\u001b[0m, in \u001b[0;36mA2PMethod.__get_valid_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    843\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray-like provided in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the (n_samples, n_features) shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m     )\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray-like provided in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Array-like provided in 'X' must be in the (n_samples, n_features) shape."
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X_adversarial = method.fit_generate(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Attack Time: {training_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50df676-fdc6-43e1-baee-33b751c1f388",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculate_performance_metrics(dnn_model, X_adversarial, y, \"full A2PM Attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb65a94-2df8-4486-8b7d-0488d18c4b51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "adv_samples_num = int(955009*0.10/0.9) \n",
    "adv_samples_num # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d078d46-0ec2-47d1-af45-717f0a7ab39f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_adversarial_indices = np.random.choice(X_adversarial.shape[0], size=adv_samples_num, replace=False)\n",
    "X_adversarial_sampled = X_adversarial[X_adversarial_indices]\n",
    "\n",
    "y_adv = np.full(adv_samples_num, 5)\n",
    "y_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d2ad4-56a3-4056-b76b-0c780559c826",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_new = X.copy()\n",
    "y_new = y.copy()\n",
    "\n",
    "X_combined = np.vstack((X_new, X_adversarial_sampled))\n",
    "y_combined = np.concatenate((y_new, y_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d425e2a-2de9-4e88-99e2-374eb497e73f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61fe40-b540-4c89-a53c-d74f77333b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_shape = X_train_adv.shape[1]\n",
    "output_shape = len(np.unique(y_train_adv))\n",
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead62dac-2ca2-4fad-b067-d05b599cca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_adv_tensor = torch.tensor(X_train_adv, dtype=torch.float32).to(device)\n",
    "y_train_adv_tensor = torch.tensor(y_train_adv, dtype=torch.long).to(device)\n",
    "\n",
    "# X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "# y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_adv_tensor, y_train_adv_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "dnn_model_protected = DNNModel(input_size=input_shape, output_size=output_shape).to(device)\n",
    "\n",
    "# Compile model\n",
    "optimizer = optim.Adam(dnn_model_protected.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping variables\n",
    "min_delta = 0.001\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(15):\n",
    "    dnn_model_protected.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = dnn_model_protected(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    dnn_model_protected.eval()\n",
    "    val_train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = dnn_model_protected(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_train_loss / len(train_loader)\n",
    "    val_accuracy = correct_predictions / len(train_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping check using min_delta\n",
    "    if best_loss - avg_val_loss > min_delta:\n",
    "        best_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e5f22-2faa-4917-b721-0f2f46041d5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model_xgb_protected = XGBClassifier()\n",
    "\n",
    "# # param_grid = {\n",
    "# #     # 'n_estimators': [10, 50, 100],\n",
    "# #     # 'max_depth': [None, 50, 100],\n",
    "# #     # 'n_estimators': [10],\n",
    "# #     # 'max_depth': [None],\n",
    "# # }\n",
    "\n",
    "# # grid_search_xgb_protected = GridSearchCV(model_xgb_protected, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
    "# # grid_search_xgb_protected.fit(X_train_adv, y_train_adv)\n",
    "\n",
    "# # print(\"Best parameters found: \", grid_search_xgb.best_params_)\n",
    "# input_shape = X_train.shape[1:]\n",
    "# num_classes = len(np.unique(y_train))\n",
    "\n",
    "\n",
    "# dnn_model_protected = Sequential()\n",
    "# dnn_model_protected.add(Input(shape=input_shape))\n",
    "# dnn_model_protected.add(Dense(units=30, activation='relu'))\n",
    "# dnn_model_protected.add(Dense(units=20, activation='relu'))\n",
    "# dnn_model_protected.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# opt = SGD(learning_rate=0.01)\n",
    "\n",
    "# dnn_model_protected.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "# hist = dnn_model_protected.fit(X_train_adv, y_train_adv, epochs=15, batch_size=64,\n",
    "#                      # validation_data=(x_val, y_val),\n",
    "#                      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4926ae-6afe-4523-bbeb-f880462d155c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dnn_model_protected = grid_search_xgb_protected.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3df939-e221-4d28-b39b-dffd689391fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_adversarial_unseen = X_adversarial[np.logical_not(np.isin(np.arange(X_adversarial.shape[0]), X_adversarial_indices))]\n",
    "len(X_adversarial_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693cbf1c-ba01-40e1-8dea-5b0ae69c0f91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "protected_adversarial_preds = dnn_model_protected.predict(X_adversarial_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52636ec-f89a-42f6-9f4e-0b3a236ef650",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_adv_full = np.full(len(X_adversarial_unseen), 5)\n",
    "\n",
    "positive_class = 5\n",
    "y_test_binary = (y_adv_full == positive_class).astype(int)\n",
    "adversarial_preds_binary = (protected_adversarial_preds == positive_class).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf9422-77d7-4b86-ab53-d38ef07f8638",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adversarial_accuracy = accuracy_score(y_test_binary, adversarial_preds_binary)\n",
    "adversarial_precision = precision_score(y_test_binary, adversarial_preds_binary, average='binary')\n",
    "adversarial_recall = recall_score(y_test_binary, adversarial_preds_binary, average='binary')\n",
    "adversarial_f1 = f1_score(y_test_binary, adversarial_preds_binary, average='binary')\n",
    "\n",
    "print(f\"Adversarial Accuracy: {adversarial_accuracy * 100:.2f}%\")\n",
    "print(f\"Adversarial Precision: {adversarial_precision * 100:.2f}%\")\n",
    "print(f\"Adversarial Recall: {adversarial_recall * 100:.2f}%\")\n",
    "print(f\"Adversarial F1 Score: {adversarial_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a5d29-b6a8-4bff-ad48-f6433d6e88c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculate_performance_metrics(dnn_model, X_test_adv, y_test_adv, \"no Adv Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16130e47-2c24-4fbc-8bbf-84fe1c5ddeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_performance_metrics(dnn_model_protected, X_test_adv, y_test_adv, \"w/ Adv Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
