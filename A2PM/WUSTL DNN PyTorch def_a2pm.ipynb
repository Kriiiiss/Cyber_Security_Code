{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6fb0050-7837-4d41-baaf-a2805d8d69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from art.attacks.evasion import SimBA, SpatialTransformation, DeepFool, BasicIterativeMethod, FastGradientMethod, ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b20c385f-f76b-4627-a3cb-e6c6331aff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {\n",
    "            \"model\" : '',\n",
    "            \"attack_model\": '',\n",
    "            'epsilon': '',\n",
    "            'Accuracy': '',\n",
    "            'Macro Precision': '',\n",
    "            'Weighted Precision': '',\n",
    "            'Macro Recall': '',\n",
    "            'Weighted Recall': '',\n",
    "            'Macro F1': '',\n",
    "            'Weighted F1': '',\n",
    "            # 'Macro AUC': '',\n",
    "            # 'Weighted AUC': '',\n",
    "            'TPR': '',\n",
    "            'FNR': '',\n",
    "            'TNR': '',\n",
    "            'FPR': '',\n",
    "        }\n",
    "head = pd.DataFrame([head])\n",
    "head.to_csv(\"/home/jovyan/A2PM/defensedmodel.csv\", mode='a', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979d2e2a-6c6c-487b-bbfb-2116caa65475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_performance_metrics(X_test, y_true, model, model_name, attack_name, eps):\n",
    "#     model.eval()\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     model.to(device)\n",
    "    \n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     probabilities = []\n",
    "\n",
    "#     num_classes = len(np.unique(y_true))\n",
    "    \n",
    "#     X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "#     y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "#     test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "#     test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             preds = torch.argmax(outputs, dim=1)\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "#         all_preds = np.array(all_preds)\n",
    "#         all_labels = np.array(all_labels)\n",
    "#         probabilities = np.array(probabilities)\n",
    "        \n",
    "#         accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "#         precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "#         precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "#         # macro_auc = roc_auc_score(label_binarize(all_labels, classes=range(num_classes)), probabilities[:,1], average='macro')\n",
    "#         # weighted_auc = roc_auc_score(label_binarize(all_labels, classes=range(num_classes)), probabilities[:,1], average='weighted')\n",
    "\n",
    "#         cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "#         def calculate_class_metrics_macro(cm, class_index):\n",
    "#             TP = cm[class_index, class_index]\n",
    "#             FP = cm[:, class_index].sum() - TP\n",
    "#             FN = cm[class_index, :].sum() - TP\n",
    "#             TN = cm.sum() - (TP + FP + FN)\n",
    "            \n",
    "#             TPR = TP / (TP + FN) if (TP + FN) != 0 else 0  \n",
    "#             TNR = TN / (TN + FP) if (TN + FP) != 0 else 0  \n",
    "#             FPR = FP / (FP + TN) if (FP + TN) != 0 else 0  \n",
    "#             FNR = FN / (FN + TP) if (FN + TP) != 0 else 0  \n",
    "            \n",
    "#             return TPR, TNR, FPR, FNR\n",
    "            \n",
    "#         metrics = np.array([calculate_class_metrics_macro(cm, i) for i in range(num_classes)])\n",
    "#         TPR_macro, TNR_macro, FPR_macro, FNR_macro = np.mean(metrics, axis=0)\n",
    "\n",
    "#         print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "#         print(\"\\nmacro\")\n",
    "#         print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "    \n",
    "#         print(\"\\nweighted\")\n",
    "#         print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "#         print()\n",
    "        \n",
    "#         print(f\"Mean FNR: {FNR_macro}\\nMean TNR: {TNR_macro}\\nMean FPR: {FPR_macro}\\nMean TPR: {TPR_macro}\")\n",
    "\n",
    "#         new_row = {\n",
    "#             \"model\" : model_name,\n",
    "#             \"attack_model\" : attack_name,\n",
    "#             'epsilon': eps,\n",
    "#             'Accuracy': accuracy,\n",
    "#             'Macro Precision': precision_macro,\n",
    "#             'Weighted Precision': precision_weighted,\n",
    "#             'Macro Recall': recall_macro,\n",
    "#             'Weighted Recall': recall_weighted,\n",
    "#             'Macro F1': f1_macro,\n",
    "#             'Weighted F1': f1_weighted,\n",
    "#             # 'Macro AUC': macro_auc,\n",
    "#             # 'Weighted AUC': weighted_auc,\n",
    "#             'TPR': TPR_macro,\n",
    "#             'FNR': FNR_macro,\n",
    "#             'TNR': TNR_macro,\n",
    "#             'FPR': FPR_macro,\n",
    "#         }\n",
    "#         new_row_df = pd.DataFrame([new_row])\n",
    "#         new_row_df.to_csv(\"/home/jovyan/A2PM/defensedmodel.csv\", mode='a', index=False, header=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb14def-c085-43f6-80b5-872fbd229c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c2d261-3906-4f67-9168-721a6f96f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('/home/jovyan/Wustl_iiot/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/Wustl_iiot/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/Wustl_iiot/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Wustl_iiot/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Wustl_iiot/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Wustl_iiot/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f7717e-657a-4325-9a1a-3c0ed00c2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "output_shape = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc49cbd6-8bb8-498f-aa92-fb52c3021842",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2effc4e2-3f0a-4e9b-bb87-3d191a49065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNNModel(input_size=input_shape, output_size=output_shape).to(device)\n",
    "model.load_state_dict(torch.load(\"/home/jovyan/Wustl_iiot/transfer_attack/dnn_pytorch.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "999ab67e-b965-484a-b3ac-c4ea800e0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80eae459-50be-4f63-b491-eafe6fcb77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(-5, 5),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(input_shape,),\n",
    "    nb_classes=output_shape,\n",
    "    device_type='gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "862c333f-3f78-4c84-9c4c-508612fb2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(model, X_test, y_test, type):\n",
    "    metrics_weighted(model, X_test, y_test, type)\n",
    "    metrics_macro(model, X_test, y_test, type)\n",
    "\n",
    "def metrics_macro(model, X_test, y_test, type):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    data = {\n",
    "    \"Metric\": [\"Accuracy\", \"Macro Precision\", \"Macro Recall\", \"Macro F1 Score\"],\n",
    "    type: [accuracy, precision, recall, f1]\n",
    "    }\n",
    "    \n",
    "    # Creating DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Saving to CSV\n",
    "    csv_file_path = \"/home/jovyan/A2PM/defensedmodel.csv\"\n",
    "    df.to_csv(csv_file_path, mode='a', index=False)\n",
    "\n",
    "    print(type)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Macro Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Macro Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"Macro F1 Score: {f1 * 100:.2f}%\")\n",
    "    \n",
    "def metrics_weighted(model, X_test, y_test, type):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    data = {\n",
    "    \"Metric\": [\"Accuracy\", \"Weighted Precision\", \"Weighted Recall\", \"Weighted F1 Score\"],\n",
    "    type: [accuracy, precision, recall, f1]\n",
    "    }\n",
    "    \n",
    "    # Creating DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Saving to CSV\n",
    "    csv_file_path = \"/home/jovyan/A2PM/defensedmodel.csv\"\n",
    "    df.to_csv(csv_file_path, mode='a', index=False)\n",
    "\n",
    "    print(type)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Weighted Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"Weighted F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dea6f03-a2e3-4897-abda-31ba4827a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_binary_columns(X_train):\n",
    "    binary_columns = []\n",
    "    for col in range(X_train.shape[1]):\n",
    "        unique_values = np.unique(X_train[:, col])\n",
    "        if set(unique_values).issubset({0, 1}):\n",
    "            binary_columns.append(col)\n",
    "    return binary_columns\n",
    "\n",
    "binary_columns = find_binary_columns(x_train)\n",
    "\n",
    "numerical_columns = []\n",
    "for i in range(0,42):\n",
    "    if i not in binary_columns:\n",
    "        numerical_columns.append(i)\n",
    "        \n",
    "pattern = (\n",
    "    {\n",
    "        \"type\": \"interval\",\n",
    "        \"features\": numerical_columns,\n",
    "        #\"integer_features\": list(range(10, 20)),\n",
    "        \"ratio\": 0.1,\n",
    "        \"max_ratio\": 0.3,\n",
    "        \"missing_value\": 0.0,\n",
    "        \"probability\": 1,\n",
    "    },\n",
    "    # {\n",
    "    #     \"type\": \"combination\",\n",
    "    #     \"features\": binary_columns,\n",
    "    #     #\"locked_features\": list(range(30, 40)), # Locks some features to ensure validity. Not using this because data is .npy and unreadable\n",
    "    #     \"probability\": 0.4,\n",
    "    # },\n",
    ")\n",
    "\n",
    "# method = A2PMethod(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80603170-b5dd-4362-9980-804dfd055f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying attack: A2PM\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class Trainer with abstract method fit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying attack: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Adversarial Training\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# trainer = AdversarialTrainer(classifier, attack, ratio=1.0)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, nb_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     33\u001b[0m epsilon_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class Trainer with abstract method fit"
     ]
    }
   ],
   "source": [
    "# Define attack methods\n",
    "from art.attacks.evasion import SimBA, SpatialTransformation, DeepFool, BasicIterativeMethod, FastGradientMethod, ProjectedGradientDescent\n",
    "from art.defences.trainer import AdversarialTrainer, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from a2pm import A2PMethod\n",
    "from a2pm.callbacks import BaseCallback, MetricCallback, TimeCallback\n",
    "from a2pm.patterns import BasePattern, CombinationPattern, IntervalPattern\n",
    "from a2pm.wrappers import BaseWrapper, KerasWrapper, SklearnWrapper, TorchWrapper\n",
    "\n",
    "attacks = {\n",
    "    # 'FGSM': FastGradientMethod(estimator=classifier, eps=0.3),\n",
    "    # 'BIM': BasicIterativeMethod(estimator=classifier, eps=0.3, max_iter=10),\n",
    "    # 'PGD': ProjectedGradientDescent(estimator=classifier, eps=0.3, max_iter=10),\n",
    "    # 'DF': DeepFool(classifier=classifier, max_iter=10),\n",
    "    'A2PM': A2PMethod(pattern),\n",
    "}\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each attack and apply adversarial training with each defense\n",
    "for attack_name, attack in attacks.items():\n",
    "    print(f\"Applying attack: {attack_name}\")\n",
    "\n",
    "    # Adversarial Training\n",
    "    # trainer = AdversarialTrainer(classifier, attack, ratio=1.0)\n",
    "    trainer = Trainer(classifier)\n",
    "\n",
    "    trainer.fit(x_train, y_train, nb_epochs=5, batch_size=128)\n",
    "\n",
    "    \n",
    "    epsilon_values = [0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "    for epsilon in epsilon_values:\n",
    "        X = f'/home/jovyan/A2PM/A2PM_adv_sample/A2PM_{epsilon}_fullattack_X.npy'\n",
    "        x_test_adv = np.load(X)\n",
    "        y = f'/home/jovyan/A2PM/A2PM_adv_sample/A2PM_{epsilon}_fullattack_y.npy'\n",
    "        y_test_adv = np.load(y)\n",
    "    \n",
    "        type = f\"DNN_defensed_{attack_name}_{epsilon}\"\n",
    "        calculate_performance_metrics(trainer, x_test_adv, y_test, type)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "635e010b-60aa-4bac-87e0-cd612a4c184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN_defensed_FGSM_0.01\n",
      "Accuracy: 99.98%\n",
      "Weighted Precision: 99.98%\n",
      "Weighted Recall: 99.98%\n",
      "Weighted F1 Score: 99.98%\n",
      "DNN_defensed_FGSM_0.01\n",
      "Accuracy: 99.98%\n",
      "Macro Precision: 99.56%\n",
      "Macro Recall: 86.22%\n",
      "Macro F1 Score: 91.43%\n",
      "DNN_defensed_FGSM_0.1\n",
      "Accuracy: 99.96%\n",
      "Weighted Precision: 99.96%\n",
      "Weighted Recall: 99.96%\n",
      "Weighted F1 Score: 99.95%\n",
      "DNN_defensed_FGSM_0.1\n",
      "Accuracy: 99.96%\n",
      "Macro Precision: 99.37%\n",
      "Macro Recall: 85.67%\n",
      "Macro F1 Score: 91.06%\n",
      "DNN_defensed_FGSM_0.2\n",
      "Accuracy: 98.67%\n",
      "Weighted Precision: 99.17%\n",
      "Weighted Recall: 98.67%\n",
      "Weighted F1 Score: 98.88%\n",
      "DNN_defensed_FGSM_0.2\n",
      "Accuracy: 98.67%\n",
      "Macro Precision: 53.50%\n",
      "Macro Recall: 70.63%\n",
      "Macro F1 Score: 57.08%\n",
      "DNN_defensed_FGSM_0.3\n",
      "Accuracy: 20.34%\n",
      "Weighted Precision: 98.76%\n",
      "Weighted Recall: 20.34%\n",
      "Weighted F1 Score: 31.78%\n",
      "DNN_defensed_FGSM_0.3\n",
      "Accuracy: 20.34%\n",
      "Macro Precision: 41.09%\n",
      "Macro Recall: 44.92%\n",
      "Macro F1 Score: 26.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98af0b-d966-4c90-86fa-e2c059b4a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "# from art.attacks.evasion import (\n",
    "#     FastGradientMethod, BasicIterativeMethod, ProjectedGradientDescent,\n",
    "#     DeepFool, SaliencyMapMethod, ElasticNet\n",
    "# )\n",
    "# from art.estimators.classification import PyTorchClassifier\n",
    "# from art.defences.trainer import AdversarialTrainer\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "# import time\n",
    "\n",
    "# # Load the arrays from the .npz file\n",
    "# data = np.load('data_arrays.npz')\n",
    "# x_train = data['X_train']\n",
    "# x_test = data['X_test']\n",
    "# x_val = data['X_val']\n",
    "# y_train = data['y_train']\n",
    "# y_test = data['y_test']\n",
    "# y_val = data['y_val']\n",
    "\n",
    "# X_combined = np.concatenate((x_train, x_test, x_val), axis=0)\n",
    "# y_combined = np.concatenate((y_train, y_test, y_val), axis=0)\n",
    "\n",
    "# # Define DNN Model\n",
    "# class DNNModel(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(DNNModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 50)\n",
    "#         self.fc2 = nn.Linear(50, 30)\n",
    "#         self.fc3 = nn.Linear(30, 20)\n",
    "#         self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.relu(self.fc3(x))\n",
    "#         x = self.fc4(x)\n",
    "#         return x\n",
    "\n",
    "# # Initialize the model\n",
    "# input_size = X_combined.shape[1]\n",
    "# output_size = len(np.unique(y_combined))\n",
    "\n",
    "# # Check if GPU is available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = DNNModel(input_size, output_size).to(device)\n",
    "# model.load_state_dict(torch.load(\"dnn_pytorch.pt\", map_location=device))\n",
    "# model.eval()\n",
    "\n",
    "# # Define function to find binary columns\n",
    "# def find_binary_columns(X_train):\n",
    "#     binary_columns = []\n",
    "#     for col in range(X_train.shape[1]):\n",
    "#         unique_values = np.unique(X_train[:, col])\n",
    "#         if set(unique_values).issubset({0, 1}):\n",
    "#             binary_columns.append(col)\n",
    "#     return binary_columns\n",
    "\n",
    "# binary_columns = find_binary_columns(x_train)\n",
    "# numerical_columns = [i for i in range(X_combined.shape[1]) if i not in binary_columns]\n",
    "\n",
    "# # Define ART classifier\n",
    "# classifier = PyTorchClassifier(\n",
    "#     model=model,\n",
    "#     input_shape=(input_size,),\n",
    "#     loss=nn.CrossEntropyLoss(),\n",
    "#     nb_classes=output_size,\n",
    "#     optimizer=optim.Adam(model.parameters(), lr=0.01),\n",
    "#     device_type='gpu' if torch.cuda.is_available() else 'cpu'\n",
    "# )\n",
    "\n",
    "# # Define attack methods\n",
    "# attacks = {\n",
    "#     # 'FGSM': FastGradientMethod(estimator=classifier, eps=0.2),\n",
    "#     # 'BIM': BasicIterativeMethod(estimator=classifier, eps=0.2, max_iter=10),\n",
    "#     # 'PGD': ProjectedGradientDescent(estimator=classifier, eps=0.2, max_iter=10),\n",
    "#     'DF': DeepFool(classifier=classifier, max_iter=10)\n",
    "# }\n",
    "\n",
    "# # List to store results\n",
    "# results = []\n",
    "\n",
    "# # Loop through each attack and apply adversarial training\n",
    "# for attack_name, attack in attacks.items():\n",
    "#     print(f\"Applying attack: {attack_name}\")\n",
    "\n",
    "#     # Adversarial Training\n",
    "#     trainer = AdversarialTrainer(classifier, attack, ratio=1.0)\n",
    "#     trainer.fit(X_combined, y_combined, nb_epochs=10, batch_size=64)\n",
    "\n",
    "#     # Generate adversarial examples\n",
    "#     X_adversarial = attack.generate(x=X_combined)\n",
    "\n",
    "#     # Convert data to tensor and move to GPU if available\n",
    "#     X_adversarial_tensor = torch.tensor(X_adversarial, dtype=torch.float32).to(device)\n",
    "#     y_combined_tensor = torch.tensor(y_combined, dtype=torch.long).to(device)\n",
    "\n",
    "#     # Predict using the classifier\n",
    "#     preds_indices = classifier.predict(X_adversarial_tensor)\n",
    "#     preds_indices_np = preds_indices.argmax(axis=1)\n",
    "\n",
    "#     # Calculate precision, recall, and F1-score\n",
    "#     precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n",
    "#         y_combined, preds_indices_np, average='micro')\n",
    "#     precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n",
    "#         y_combined, preds_indices_np, average='macro')\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     acc = np.mean(preds_indices_np == y_combined)\n",
    "\n",
    "#     # Compute the confusion matrix and derived metrics\n",
    "#     conf_matrix = confusion_matrix(y_combined, preds_indices_np)\n",
    "#     FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)\n",
    "#     FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "#     TP = np.diag(conf_matrix)\n",
    "#     TN = conf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "#     TPR = TP / (TP + FN)  # True Positive Rate\n",
    "#     TNR = TN / (TN + FP)  # True Negative Rate\n",
    "#     FPR = FP / (FP + TN)  # False Positive Rate\n",
    "#     FNR = FN / (FN + TP)  # False Negative Rate\n",
    "\n",
    "#     # Calculate averages\n",
    "#     TPR_avg = np.mean(TPR)\n",
    "#     TNR_avg = np.mean(TNR)\n",
    "#     FPR_avg = np.mean(FPR)\n",
    "#     FNR_avg = np.mean(FNR)\n",
    "\n",
    "#     # Prepare a dictionary for the results\n",
    "#     result_dict = {\n",
    "#         'Attack': attack_name,\n",
    "#         'Accuracy': acc,\n",
    "#         'Micro Precision': precision_micro,\n",
    "#         'Macro Precision': precision_macro,\n",
    "#         'Micro Recall': recall_micro,\n",
    "#         'Macro Recall': recall_macro,\n",
    "#         'Micro F1 Score': fscore_micro,\n",
    "#         'Macro F1 Score': fscore_macro,\n",
    "#         'Average TNR': TNR_avg,\n",
    "#         'Average FPR': FPR_avg,\n",
    "#         'Average FNR': FNR_avg,\n",
    "#         'Macro TNR': TNR_avg,\n",
    "#         'Macro FNR': FNR_avg,\n",
    "#         'Macro FPR': FPR_avg\n",
    "#     }\n",
    "\n",
    "#     # Add results to the list\n",
    "#     results.append(result_dict)\n",
    "\n",
    "# # Convert results to DataFrame and save to CSV\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv('adversarial_trainer_results.csv', index=False)\n",
    "\n",
    "# print(\"All results have been saved to adversarial_defenses_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
