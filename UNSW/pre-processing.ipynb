{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install pyarrow\n",
    "# !pip install numpy\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yBcwWIT3xfs1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2097,
     "status": "ok",
     "timestamp": 1705034129838,
     "user": {
      "displayName": "Kris Chen",
      "userId": "14019901183015848448"
     },
     "user_tz": 480
    },
    "id": "FkEjK12Fw812"
   },
   "outputs": [],
   "source": [
    "# dftrain = pd.read_csv(\"/home/jovyan/UNSW/UNSW_NB15_training.csv\") \n",
    "# dftest = pd.read_csv(\"/home/jovyan/UNSW/UNSW_NB15_testing.csv\")\n",
    "# # simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# dftrain = dftrain.drop('id', axis=1)\n",
    "# dftest = dftest.drop('id', axis=1)\n",
    "\n",
    "\n",
    "# dftrain = shuffle(dftrain)\n",
    "# label_encoder = LabelEncoder()\n",
    "# dftrain['proto'] = label_encoder.fit_transform(dftrain['proto'])\n",
    "# dftrain['service'] = label_encoder.fit_transform(dftrain['service'])\n",
    "# dftrain['state'] = label_encoder.fit_transform(dftrain['state'])\n",
    "\n",
    "# dftest = shuffle(dftest)\n",
    "# label_encoder = LabelEncoder()\n",
    "# dftest['proto'] = label_encoder.fit_transform(dftest['proto'])\n",
    "# dftest['service'] = label_encoder.fit_transform(dftest['service'])\n",
    "# dftest['state'] = label_encoder.fit_transform(dftest['state'])\n",
    "\n",
    "# #train\n",
    "# #print(dftrain.loc[dftrain['target'] == 'legitimate'])\n",
    "# # class_names = dftrain.target.unique()\n",
    "# # dftrain=dftrain.astype('category')\n",
    "# # cat_columns = dftrain.select_dtypes(['category']).columns\n",
    "# # dftrain[cat_columns] = dftrain[cat_columns].apply(lambda x: x.cat.codes)\n",
    "# #print(dftrain.loc[125, 'target'])\n",
    "# x_columns = dftrain.columns.drop('attack_cat')\n",
    "# x_train = dftrain[x_columns].values\n",
    "\n",
    "# #test\n",
    "# # class_names = dftest.target.unique()\n",
    "# # dftest=dftest.astype('category')\n",
    "# # cat_columns = dftest.select_dtypes(['category']).columns\n",
    "# # dftest[cat_columns] = dftest[cat_columns].apply(lambda x: x.cat.codes)\n",
    "# x_columns = dftest.columns.drop('attack_cat')\n",
    "# x_test = dftest[x_columns].values\n",
    "\n",
    "# y_train = dftrain['attack_cat']\n",
    "# y_test = dftest['attack_cat']\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train = label_encoder.fit_transform(y_train)\n",
    "# y_test = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/jovyan/UNSW/UNSW_NB15_training.csv\") \n",
    "\n",
    "list_drop = ['id','attack_cat']\n",
    "df.drop(list_drop,axis=1,inplace=True)\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "# df_numeric.describe(include='all')\n",
    "\n",
    "DEBUG =0\n",
    "\n",
    "for feature in df_numeric.columns:\n",
    "    if DEBUG == 1:\n",
    "        print(feature)\n",
    "        print('max = '+str(df_numeric[feature].max()))\n",
    "        print('75th = '+str(df_numeric[feature].quantile(0.95)))\n",
    "        print('median = '+str(df_numeric[feature].median()))\n",
    "        print(df_numeric[feature].max()>10*df_numeric[feature].median())\n",
    "        print('----------------------------------------------------')\n",
    "    if df_numeric[feature].max()>10*df_numeric[feature].median() and df_numeric[feature].max()>10 :\n",
    "        df[feature] = np.where(df[feature]<df[feature].quantile(0.95), df[feature], df[feature].quantile(0.95))\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "# df_numeric.describe(include='all')\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "df_before = df_numeric.copy()\n",
    "DEBUG = 0\n",
    "for feature in df_numeric.columns:\n",
    "    if DEBUG == 1:\n",
    "        print(feature)\n",
    "        print('nunique = '+str(df_numeric[feature].nunique()))\n",
    "        print(df_numeric[feature].nunique()>50)\n",
    "        print('----------------------------------------------------')\n",
    "    if df_numeric[feature].nunique()>50:\n",
    "        if df_numeric[feature].min()==0:\n",
    "            df[feature] = np.log(df[feature]+1)\n",
    "        else:\n",
    "            df[feature] = np.log(df[feature])\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "# df_cat.describe(include='all')\n",
    "\n",
    "DEBUG = 0\n",
    "for feature in df_cat.columns:\n",
    "    if DEBUG == 1:\n",
    "        print(feature)\n",
    "        print('nunique = '+str(df_cat[feature].nunique()))\n",
    "        print(df_cat[feature].nunique()>6)\n",
    "        print(sum(df[feature].isin(df[feature].value_counts().head().index)))\n",
    "        print('----------------------------------------------------')\n",
    "    \n",
    "    if df_cat[feature].nunique()>6:\n",
    "        df[feature] = np.where(df[feature].isin(df[feature].value_counts().head().index), df[feature], '-')\n",
    "\n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "# df_cat.describe(include='all')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "# X.head()\n",
    "feature_names = list(X.columns)\n",
    "# np.shape(X)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,2,3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "for label in list(df_cat['state'].value_counts().index)[::-1][1:]:\n",
    "    feature_names.insert(0,label)\n",
    "    \n",
    "for label in list(df_cat['service'].value_counts().index)[::-1][1:]:\n",
    "    feature_names.insert(0,label)\n",
    "    \n",
    "for label in list(df_cat['proto'].value_counts().index)[::-1][1:]:\n",
    "    feature_names.insert(0,label)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#                                                     test_size = 0, \n",
    "#                                                     random_state = 0,\n",
    "#                                                     stratify=y)\n",
    "x_train = X\n",
    "y_train = y\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train[:, 18:] = sc.fit_transform(x_train[:, 18:])\n",
    "# X_test[:, 18:] = sc.transform(X_test[:, 18:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/jovyan/UNSW/UNSW_NB15_testing.csv\")\n",
    "\n",
    "list_drop = ['id','attack_cat']\n",
    "df.drop(list_drop,axis=1,inplace=True)\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "# df_numeric.describe(include='all')\n",
    "\n",
    "DEBUG =0\n",
    "\n",
    "for feature in df_numeric.columns:\n",
    "    if DEBUG == 1:\n",
    "        print(feature)\n",
    "        print('max = '+str(df_numeric[feature].max()))\n",
    "        print('75th = '+str(df_numeric[feature].quantile(0.95)))\n",
    "        print('median = '+str(df_numeric[feature].median()))\n",
    "        print(df_numeric[feature].max()>10*df_numeric[feature].median())\n",
    "        print('----------------------------------------------------')\n",
    "    if df_numeric[feature].max()>10*df_numeric[feature].median() and df_numeric[feature].max()>10 :\n",
    "        df[feature] = np.where(df[feature]<df[feature].quantile(0.95), df[feature], df[feature].quantile(0.95))\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "# df_numeric.describe(include='all')\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "df_before = df_numeric.copy()\n",
    "DEBUG = 0\n",
    "for feature in df_numeric.columns:\n",
    "    if DEBUG == 1:\n",
    "        print(feature)\n",
    "        print('nunique = '+str(df_numeric[feature].nunique()))\n",
    "        print(df_numeric[feature].nunique()>50)\n",
    "        print('----------------------------------------------------')\n",
    "    if df_numeric[feature].nunique()>50:\n",
    "        if df_numeric[feature].min()==0:\n",
    "            df[feature] = np.log(df[feature]+1)\n",
    "        else:\n",
    "            df[feature] = np.log(df[feature])\n",
    "\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "# df_cat.describe(include='all')\n",
    "\n",
    "DEBUG = 0\n",
    "for feature in df_cat.columns:\n",
    "    if DEBUG == 1:\n",
    "        print(feature)\n",
    "        print('nunique = '+str(df_cat[feature].nunique()))\n",
    "        print(df_cat[feature].nunique()>6)\n",
    "        print(sum(df[feature].isin(df[feature].value_counts().head().index)))\n",
    "        print('----------------------------------------------------')\n",
    "    \n",
    "    if df_cat[feature].nunique()>6:\n",
    "        df[feature] = np.where(df[feature].isin(df[feature].value_counts().head().index), df[feature], '-')\n",
    "\n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "# df_cat.describe(include='all')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "# X.head()\n",
    "feature_names = list(X.columns)\n",
    "# np.shape(X)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,2,3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "for label in list(df_cat['state'].value_counts().index)[::-1][1:]:\n",
    "    feature_names.insert(0,label)\n",
    "    \n",
    "for label in list(df_cat['service'].value_counts().index)[::-1][1:]:\n",
    "    feature_names.insert(0,label)\n",
    "    \n",
    "for label in list(df_cat['proto'].value_counts().index)[::-1][1:]:\n",
    "    feature_names.insert(0,label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_test, x_val, y_test, y_val = train_test_split(X, y, \n",
    "                                                    test_size = 0.35, \n",
    "                                                    random_state = 0,\n",
    "                                                    stratify=y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_val[:, 18:] = sc.fit_transform(x_val[:, 18:])\n",
    "x_test[:, 18:] = sc.transform(x_test[:, 18:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "np.save('/home/jovyan/UNSW/x_train.npy', x_train)\n",
    "np.save('/home/jovyan/UNSW/y_train.npy', y_train)\n",
    "np.save('/home/jovyan/UNSW/x_val.npy', x_train)\n",
    "np.save('/home/jovyan/UNSW/y_val.npy', y_train)\n",
    "np.save('/home/jovyan/UNSW/x_test.npy', x_test)\n",
    "np.save('/home/jovyan/UNSW/y_test.npy', y_test)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNNv8T4vA6/2+/ypCce0gGR",
   "mount_file_id": "1fpPzLxt4vkgz2Q8y97GQC034tGPU6BAG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
