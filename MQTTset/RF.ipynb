{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2538,
     "status": "ok",
     "timestamp": 1705028302836,
     "user": {
      "displayName": "Kris Chen",
      "userId": "14019901183015848448"
     },
     "user_tz": 480
    },
    "id": "gmdMhUwtmyNi"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score as f1_score_rep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4935,
     "status": "ok",
     "timestamp": 1705028338792,
     "user": {
      "displayName": "Kris Chen",
      "userId": "14019901183015848448"
     },
     "user_tz": 480
    },
    "id": "y4UnOwL8xGVW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_test = np.load('/home/jovyan/MQTTset/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/MQTTset/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/MQTTset/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/MQTTset/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/MQTTset/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/MQTTset/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2369003,
     "status": "ok",
     "timestamp": 1699996082808,
     "user": {
      "displayName": "Jing Chen",
      "userId": "06187300512739488624"
     },
     "user_tz": 480
    },
    "id": "lcFU8-ZQw4rZ",
    "outputId": "727dfa00-ed05-4233-d336-666b3e140452"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 请确保已经加载了 x_train, y_train, x_test, y_test, x_val, y_val\n",
    "\n",
    "# 定义参数\n",
    "rf_params = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # 树的数量\n",
    "    'max_depth': [5, 10, None],  # 树的最大深度\n",
    "    'min_samples_split': [2, 4],  # 分割所需的最小样本数\n",
    "    # 'min_samples_leaf': range(1, 21)  # 叶节点的最小样本数\n",
    "}\n",
    "\n",
    "# # 确保结果目录存在\n",
    "# result_dir = Path('/content/drive/MyDrive/Data/results')\n",
    "# if not result_dir.exists():\n",
    "#     result_dir.mkdir()\n",
    "\n",
    "def tune_with_halving_grid_search_rf(x_train, y_train, param_grid):\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    start = time()\n",
    "    halving_rf_results = HalvingGridSearchCV(\n",
    "        rf,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        factor=2,\n",
    "        min_resources='exhaust',\n",
    "        scoring='f1_weighted'\n",
    "    ).fit(x_train, y_train)\n",
    "\n",
    "    duration = time() - start\n",
    "\n",
    "    results = pd.DataFrame(halving_rf_results.cv_results_)\n",
    "    # results.to_csv(result_dir / 'halving_rf_results.csv')\n",
    "\n",
    "    # 格式化和排序结果\n",
    "    results = results.loc[:, ('iter', 'rank_test_score', 'mean_test_score', 'params')]\n",
    "    results.sort_values(by=['iter', 'rank_test_score'], ascending=[False, True], inplace=True)\n",
    "\n",
    "    return results, duration\n",
    "\n",
    "# 使用验证数据集进行参数调整\n",
    "halving_results, halving_duration = tune_with_halving_grid_search_rf(x_val, y_val, rf_params)\n",
    "\n",
    "print(halving_results.head())\n",
    "\n",
    "# 获取最佳参数和分数\n",
    "best_score = halving_results['mean_test_score'].iloc[0]\n",
    "best_params = halving_results['params'].iloc[0]\n",
    "\n",
    "# 使用最佳参数训练随机森林模型\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "best_rf.fit(x_train, y_train)\n",
    "\n",
    "# 在测试集上评估\n",
    "accuracy = accuracy_score(y_test, best_rf.predict(x_test))\n",
    "micro_f1 = f1_score_rep(y_test, best_rf.predict(x_test), average=\"micro\")\n",
    "macro_f1 = f1_score_rep(y_test, best_rf.predict(x_test), average=\"macro\")\n",
    "\n",
    "# 打印结果\n",
    "print(f'Best score for HalvingGridSearchCV is {best_score:.3f}, took {halving_duration:.2f} seconds')\n",
    "print(f'Params: {best_params}')\n",
    "print(f'Corresponding test accuracy: {accuracy * 100:.2f}%')\n",
    "print(\"Micro F1 Score: \", micro_f1)\n",
    "print(\"Macro F1 Score: \", macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502154,
     "status": "ok",
     "timestamp": 1705028899314,
     "user": {
      "displayName": "Kris Chen",
      "userId": "14019901183015848448"
     },
     "user_tz": 480
    },
    "id": "XR7pQh62maht",
    "outputId": "7bc0fb2f-54f0-474d-83d1-aa61abf6402d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# best_rf = RandomForestClassifier(max_depth=10, min_samples_split=4, n_estimators= 200)\n",
    "# best_rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = best_rf.predict(x_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# tn, fp, fn, tp = conf_matrix.ravel()\n",
    "cm = conf_matrix\n",
    "fp = cm.sum(axis=0) - np.diag(cm)\n",
    "fn = cm.sum(axis=1) - np.diag(cm)\n",
    "tp = np.diag(cm)\n",
    "tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "tpr = tp / (tp + fn)\n",
    "fnr = fn / (fn + tp)\n",
    "tnr = tn / (tn + fp)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "auc = roc_auc_score(y_test, best_rf.predict_proba(x_test), multi_class='ovr')\n",
    "\n",
    "print(f\"FPR: {fpr}\")\n",
    "print(f\"TPR: {tpr}\")\n",
    "print(f\"FNR: {fnr}\")\n",
    "print(f\"TNR: {tnr}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "print(f\"FPR: {np.mean(fpr)}\")\n",
    "print(f\"tpr: {np.mean(tpr)}\")\n",
    "print(f\"fnr: {np.mean(fnr)}\")\n",
    "print(f\"tnr: {np.mean(tnr)}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=best_rf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
